{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25b2a7e-373b-4604-b2af-8742d6a7bb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Team J - Group:\n",
    "## 1) Sankalp Kuram\n",
    "## 2) Youjin Park\n",
    "## 3) Yada Klueabvichit\n",
    "## 4) Xiaoyue Huang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7629999-6c78-4b0a-a86b-b76793325d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "927fab32-3e9d-4f18-80b0-9634c14e16b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff4e7c3ca0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff4e7c3ca0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff4e7c3ca0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff4e7c3ca0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff4e7c3ca0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff4e7c3ca0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff4e7c3ca0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff4e7c3ca0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1.Extract and load the 41 comma delimited purchases data files and form a single table of purchases data; \n",
    "##   a.Preferably follow these guidelines when staging the files (this staging approach does not make sense for our data as the files are small, but it is good practice if you have more data and if the data is loaded over time)\n",
    "##   b.Use Python to automate the PUT process, e.g., use glob to iterate through and PUT all purchases files automatically\n",
    "##   c.COPY INTO is generally preferred over INSERT INTO (this applies to the entire project);\n",
    "##   d.To the extent possible, perform transformations such as selecting columns and setting data types during the COPY INTO process\n",
    "\n",
    "### Snowflake Connection\n",
    "import snowflake.connector\n",
    "\n",
    "conn = snowflake.connector.connect(\n",
    "    user='skuram',\n",
    "    password='S@nkalp16',\n",
    "    account='jja15332'\n",
    "    )\n",
    "cs = conn.cursor()\n",
    "\n",
    "## Set up the Snowflake environment \n",
    "cs.execute(\"CREATE WAREHOUSE IF NOT EXISTS ELT_Warehouse\")\n",
    "cs.execute(\"CREATE DATABASE IF NOT EXISTS ELT_Database\")\n",
    "cs.execute(\"USE DATABASE ELT_Database\")\n",
    "cs.execute(\"CREATE SCHEMA IF NOT EXISTS ELT_Schema\")\n",
    "cs.execute(\"CREATE STAGE IF NOT EXISTS ELT_Stage\")\n",
    "\n",
    "###### Fetch the Monthly PO .csv files data and load it to Snowflake ########\n",
    "\n",
    "## Use PUT to stage the .csv files\n",
    "cs.execute(\"PUT file://CaseData/MonthlyPOData/* @ELT_Schema.ELT_Stage\")\n",
    "\n",
    "## Create the Purchase_Order_Header table\n",
    "cs.execute(\n",
    "\"CREATE TABLE IF NOT EXISTS Purchase_Order_Header(PurchaseOrderID INTEGER,SupplierID INTEGER,OrderDate VARCHAR,DeliveryMethodID INTEGER,ContactPersonID INTEGER,ExpectedDeliveryDate VARCHAR,SupplierReference VARCHAR,IsOrderFinalized INTEGER,Comments STRING,InternalComments STRING,LastEditedBy STRING,LastEditedWhen VARCHAR,PurchaseOrderLineID INTEGER,StockItemID INTEGER,OrderedOuters INTEGER,Description STRING,ReceivedOuters INTEGER,PackageTypeID INTEGER,ExpectedUnitPricePerOuter FLOAT,LastReceiptDate VARCHAR,IsOrderLineFinalized INTEGER,Right_LastEditedBy STRING,Right_LastEditedWhen VARCHAR)\"\n",
    ")\n",
    "\n",
    "## Copy to the snowflake table through the staged data\n",
    "cs.execute(\"COPY INTO Purchase_Order_Header FROM @ELT_Database.ELT_Schema.ELT_Stage on_error = continue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "799d24de-2d5f-4a32-837a-eec5ac490df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff4e7c3ca0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff4e7c3ca0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2.Create a calculated field that shows purchase order totals, i.e., for each order, \n",
    "##   sum the line item amounts (defined as ReceivedOuters * ExpectedUnitPricePerOuter), \n",
    "##   and name this field POAmount\n",
    "\n",
    "cs.execute(\"\"\"DROP TABLE IF EXISTS Purchase_Order_Header_Updated\"\"\")\n",
    "\n",
    "cs.execute(\"\"\"\n",
    "CREATE TABLE Purchase_Order_Header_Updated AS \n",
    "(\n",
    "    SELECT PurchaseOrderID,SUPPLIERID,\n",
    "    sum(cast(ReceivedOuters AS INT) * ExpectedUnitPricePerOuter) AS POAmount \n",
    "    FROM Purchase_Order_Header \n",
    "    GROUP BY PurchaseOrderID,SUPPLIERID\n",
    ")\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a45ba32f-3b12-4ec5-b042-f5d6df959455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff4e7c3ca0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff4e7c3ca0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff4e7c3ca0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff4e7c3ca0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff4e7c3ca0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 3.Extract and load the supplier invoice XML data\n",
    "## a.shred the data into a table (preferably in the COPY INTO process) where each row \n",
    "## corresponds to a single invoice\n",
    "\n",
    "## Create Staging for XML file loading\n",
    "cs.execute(\"CREATE OR REPLACE STAGE ETLXMLStage\")\n",
    "cs.execute(\"CREATE OR REPLACE file format xml_load type = xml strip_outer_element = True\")\n",
    "cs.execute(\"PUT file://CaseData/Supplier_Transactions_XML.xml @ETLXMLStage\")\n",
    "\n",
    "## Creating a table Invoice XML\n",
    "cs.execute(\"CREATE OR REPLACE TABLE INVOICE_XML (src_xml VARIANT)\")\n",
    "\n",
    "## Load the invoice data to the table through staging \n",
    "cs.execute(\"COPY INTO INVOICE_XML FROM @ETLXMLStage file_format = (format_name = xml_load)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17f776a0-e0ca-4bb5-a13a-70eef0f8c889",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4.Join the purchases data from step 2 and the supplier invoices data from step 3 (only include matching rows); \n",
    "##   assuming that step 2 was completed correctly, you can assume the following relationships among the four tables\n",
    "##   (the other two tables are discussed below):\n",
    "\n",
    "cs.execute(\"\"\"CREATE OR REPLACE TABLE invoice_xml_table AS\n",
    "(SELECT \n",
    "           XMLGET(src_xml,'suppliertransactionID'):\"$\" as suppliertransactionID,\n",
    "           XMLGET(src_xml,'SupplierID'):\"$\" as SupplierID,\n",
    "           XMLGET(src_xml,'TransactionTypeID'):\"$\" as TransactionTypeID,\n",
    "           XMLGET(src_xml,'PurchaseOrderID'):\"$\" as PurchaseOrderID,\n",
    "           XMLGET(src_xml,'PaymentMethodID'):\"$\" as PaymentMethodID,\n",
    "           XMLGET(src_xml,'SupplierInvoiceNumber'):\"$\" as SupplierInvoiceNumber,\n",
    "           XMLGET(src_xml,'TransactionDate'):\"$\" as TransactionDate,\n",
    "           XMLGET(src_xml,'AmountExcludingTax'):\"$\" as AmountExcludingTax,\n",
    "           XMLGET(src_xml,'TaxAmount'):\"$\" as TaxAmount,\n",
    "           XMLGET(src_xml,'TransactionAmount'):\"$\" as TransactionAmount,\n",
    "           XMLGET(src_xml,'OutstandingBalance'):\"$\" as OutstandingBalance,\n",
    "           XMLGET(src_xml,'FinalizationDate'):\"$\" as FinalizationDate,\n",
    "           XMLGET(src_xml,'IsFinalized'):\"$\" as IsFinalized,\n",
    "           XMLGET(src_xml,'LastEditedBy'):\"$\" as LastEditedBy,\n",
    "           XMLGET(src_xml,'LastEditedWhen'):\"$\" as LastEditedWhen\n",
    "           FROM INVOICE_XML)\n",
    "\"\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9d8253d-766c-43f5-99de-697604e8c106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff4e7c3ca0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 5.Using the joined data from step 4, create a calculated field that shows the difference between  \n",
    "##   AmountExcludingTax and POAmount,name this field invoiced_vs_quoted, and save the result\n",
    "##   as a materialized view named purchase_orders_and_invoices\n",
    "##  a.If your version of Snowflake does not support materialized views then create a table instead \n",
    "##    using the join (this applies to all requirements about materialized views)\n",
    "\n",
    "\n",
    "#CREATING VIEW  purchase_orders_and_invoices\n",
    "cs.execute(\"\"\"CREATE VIEW purchase_orders_and_invoices AS\n",
    "(SELECT \n",
    "    A.*,\n",
    "    B.AMOUNTEXCLUDINGTAX,\n",
    "    (AmountExcludingTax::numeric-A.POAmount) as invoiced_as_quoted\n",
    "    FROM Purchase_Order_Header_Updated as A\n",
    "    JOIN invoice_xml_table as B\n",
    "    ON A.purchaseorderid = B.PurchaseOrderID AND A.supplierid = B.SupplierID)\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17c87ef6-8c02-4821-b2b1-ca136697b859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff4e7c3ca0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff4e7c3ca0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff4e7c3ca0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 6.Extract the supplier_case data from postgres, do not import the data into Python, instead\n",
    "## use Python to move the data from postgres to your local drive and then directly into a Snowflake stage\n",
    "## a.Consider creating a Python function that can take a csv file path as input and then generate field definitions (field names and datatypes based on the header and data types in the file) that can then be used in CREATE TABLE statement.\n",
    "## b.You need to use psycopg2 or a similar Python library to connect to the postgres database within Python, issue a command to postgres to have postgres save the supplier_case data to file, and then use cs.execute to move the file to an internal Snowflake stage and eventually into a table.\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "s = \"SELECT * from supplier_case\"\n",
    "\n",
    "connection = psycopg2.connect(database=\"rsm-docker\",user=\"jovyan\",password=\"postgres\",host=\"127.0.0.1\",port = 8765)\n",
    "cursor = connection.cursor()\n",
    "\n",
    "SQL_for_file_output = \"COPY ({0}) TO STDOUT WITH CSV HEADER\".format(s)\n",
    "\n",
    "with open(r'supplier_case.csv','w') as f_output:\n",
    "    cursor.copy_expert(SQL_for_file_output,f_output)\n",
    "\n",
    "connection.close()\n",
    "\n",
    "cs.execute(\"PUT file://supplier_case.csv @ETLXMLStage\")\n",
    "cs.execute(\"CREATE TABLE IF NOT EXISTS supplier_case(SupplierID INTEGER,SupplierName VARCHAR,SupplierCategoryID INTEGER,PrimaryContactPersonID INTEGER,AlternateContactPersonID INTEGER,DeliveryMethodID INTEGER ,PostalCityID INTEGER,SupplierReference VARCHAR,BankAccountName VARCHAR,BankAccountBranch VARCHAR,BankAccountCode INTEGER,BankAccountNumber NUMERIC,BankInternationalCode INTEGER,PaymentDays INTEGER,InternalComments VARCHAR,PhoneNumber VARCHAR,FaxNumber VARCHAR,WebsiteURL VARCHAR,DeliveryAddressLine1 VARCHAR,DeliveryAddressLine2 VARCHAR,DeliveryPostalCode INTEGER,DeliveryLocation VARCHAR,PostalAddressLine1 VARCHAR,PostalAddressLine2 VARCHAR,PostalPostalCode INTEGER,LastEditedBy INTEGER,ValidFrom VARCHAR,ValidTo VARCHAR)\")\n",
    "cs.execute(\"COPY INTO supplier_case from @ETLXMLStage on_error=continue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fbc656c8-7689-40dd-908c-daf05319e569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff4e7c3ca0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating table WEATHERDATA\n",
    "cs.execute(\"\"\"CREATE TABLE WEATHERDATA(geoid numeric, ALAND NUMERIC, AWATER NUMERIC, ALAND_SQMI NUMERIC, AWATER_SQMI NUMERIC, INTPTLAT NUMERIC, INTPTLONG NUMERIC)\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f3014c3-a486-4646-a479-dad2a5750588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff4e7c3ca0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff4e7c3ca0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff4e7c3ca0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff4e7c3ca0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding Gazzeteer files into WEATHERDATA through stage\n",
    "cs.execute(\"create or replace stage stage_weather_data\")\n",
    "cs.execute(\"create or replace file format CSVfile type=csv skip_header=1\")\n",
    "cs.execute(\"PUT 'file://Gaz_zcta_national.csv' @stage_weather_data\")\n",
    "cs.execute(\"COPY INTO WEATHERDATA from @stage_weather_data file_format=(format_name=csvfile)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7bf0a39-a6d9-48ed-8f54-f4d9a5a55f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff4e7c3ca0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 7.Connect manually inside Snowflake Marketplace to the Knoema Environment Data Atlas data \n",
    "##   (find it and click Get).  The name of the dataset that you will be using is \n",
    "##   ENVIRONMENT_DATA_ATLAS.ENVIRONMENT.NOAACD2019R) and then extract weather data for each unique \n",
    "##   zip code in the supplier_case table (suppliers can have the same zip code but you only need to \n",
    "##   extract weather data for each zip code once).\n",
    "\n",
    "#CREATE VIEW SUPPLIER_ZIP_CODE_WEATHER\n",
    "cs.execute(\"\"\"CREATE VIEW supplier_zip_code_weather as\n",
    "(select DISTINCT wd.geoid as zipcode,EDA.\"Date\",EDA.\"Value\" \n",
    "from weatherdata wd\n",
    "left join ENVIRONMENT_DATA_ATLAS.ENVIRONMENT.NOAACD2019R as EDA\n",
    "on wd.intptlat = EDA.\"Stations Latitude\"::numeric and wd.intptlong = EDA.\"Stations Longitude\"::numeric\n",
    "join supplier_case sc\n",
    "on sc.postalpostalcode = wd.geoid\n",
    "where EDA.\"Units\" = 'Fahrenheit')\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dea66852-9887-4395-a0bb-4d355e895974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff4e7c3ca0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 8.Join purchase_orders_and_invoices, supplier_case, and supplier_zip_code_weather based on zip codes \n",
    "##   and the transaction date. Only include transactions that have matching temperature readings\n",
    "\n",
    "cs.execute(\"\"\"SELECT *\n",
    "FROM Purchase_Order_Header_Updated A\n",
    "JOIN invoice_xml_table B\n",
    "ON A.purchaseorderid = B.purchaseorderid AND A.supplierid = B.supplierid\n",
    "JOIN supplier_case C\n",
    "ON B.supplierid = C.supplierid\n",
    "join supplier_zip_code_weather D \n",
    "on C.postalpostalcode::varchar = D.zipcode\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
